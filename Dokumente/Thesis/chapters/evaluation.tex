\section{Evaluation}

After all implementations were done an evaluation of the used algorithm was accomplished. Therefore different investigation areas are used applying several parameters to make an analysis of the results possible. The resolution were compared to outcomes of other geomarketing software. \\
First a comparison to a calculation in SIM Tool was done. Therefore microm provided some results doing a Greenfieldanalysis to zip-code8 areas of Hamburg. The area segmentation process was done using approximately 2500 basic areas. Thereby 200 new locations should be created. Afterwards the basic areas should be allocated to these locations. The calculation using SIM runs 1:30h. The same calculation was done using the Greenfield algorithm which was implemented within that master thesis. For making the results comparable the same dataset was used. The aim of the implemented algorithm was to create coherent, compact and well balanced territories within an adequate running time. The results of the Greenfieldanalysis using the algorithm from that thesis were achieved after 5 minutes. Contrary to the territories which were created by SIM, the here created territories were all contiguous. Additionally the territories were more balanced than the ones of SIM. Nevertheless the balance could be quite better.

\begin{figurevarSize}{Result of Greenfieldanalyses to zip-code8 areas of Hamburg. 200 locations and territories are created. Due to the high number of territories a clear coloured distinction is not possible.}{images/HH.png}{0.9}\end{figurevarSize}


Additionally a comparison to another geomarketing software called Map\&Market was done. Thereby whole Germany was used as investigation area, consequently approximately 8000 basic areas were assigned to the locations. The area segmentation was done using a Greenfieldanalyses creating ten new locations. Doing this calculation a lot of problems occurred. The biggest problem are the island in the North Sea and Baltic Sea. The islands are not connected to any other basic. Consequently they are not continuous to a territory in sense of the definition used in that master thesis because no shared edge of two basic areas exists. That is why the check of contiguous yields to errors. To solve that problem a variable was integrated that shows whether the check of coherence should be done or not. In case of using islands within the amount of basic areas no totally contiguity can be reached thus the variable needs to indicate that no check will be done. Although the check of coherence was turned of during the calculation most of the basic areas are allocated in such a way that they are contiguous. The algorithm was improved in such a way that the possibility creating incoherent territories getting smaller. Thus the results looking quite well. 


!!!!BILD!!!!!!

Although a lot of improvements concerning the performance were done the calculation time is still to high. This is caused by two facts. One fact are the number of databases access which are necessary.Before the area segmentation can start the polygons including their properties and neighbouring relationships are stored into local variables. Using 8000 basic areas these preparatory works needs up to half an hour. After this the allocation starts which needs running time again. Especially the local search needs a lot of time, thus the calculation time is higher than the one of Map\&Market. Map\&Market needs 50 minutes, the algorithm which was implemented here needs 1:20h. Nevertheless the approach of the master thesis owns some advantages compared to the one used in Map\&Market. Thus the compactness is considered and contiguity will be achieved if the data is applicable doing so. However some more improvements are still necessary. During the calculation of the two test cases some problems could be identified especially concerning performance. To make the algorithm much faster a lot of improvements were done. First of all the number of accesses to the database needs to be reduced. Therefore a lot of queries were removed. Instead of this just one access to the database in the beginning was used which stores all necessary data. This one is just one example of enhancement that were done. \\
Additionally to the two comparisons of use cases the algorithms were tested to different investigation areas using several parameters. Thereby some weaknesses could be determined. Especially the implementation of the local search yields to a lot of problems. They are caused by rearranging same basic areas again and again so that no better balanced will be achieved. That is why an abortion was implemented after a determined running time or number of rearrangements. This problems leads to two weaknesses. First it may be happen that the predefined balance threshold will be not reached. Consequently the territories are not well balanced. Second the running time may be still high although no better balanced is achieved. That is why an advancement of that algorithm is still necessary in future work. However the implemented algorithms for area segmentation, Whitespotanalyses and Greenfieldanalyses are good prototypes doing area segmentation. Compared to other applications they yield to convincing results within an adequate running time. Nevertheless some improvements are necessary concerning the balance and the performance. Additionally it is not satisfied that an optimal solution of area segmentation is found, but therefore the running time is still fast. 

